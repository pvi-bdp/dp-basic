version: "3.8" 

services:

  ansible:
#    image: da-platform/ansible:2.9.3-alpine-latest
    image: megoldsby/da-platform:ansible-2.9.3-alpine-latest
    container_name: ansible
    volumes:
     - ${DP_INPUT_SETUP_DIR}/ansible-playbooks:/ansible/playbooks
#    entrypoint: /bin/bash

  hdfs-client:
#    image: da-platform/h-hive-server:2.3.8
    image: megoldsby/da-platform:h-hive-server-2.3.8
    container_name: hdfs-client
    volumes:
     - ${DP_INPUT_SETUP_DIR}:/opt/data/data-setup
    command: /bin/bash

  spark-client:
#    image: da-platform/spark-client:2.4.3-hadoop2.10.1-java8
    image: megoldsby/da-platform:spark-client-2.4.3-hadoop2.10.1-java8
    container_name: spark_client
    environment:
      - SPARK_MASTER=yarn
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file:
      - ./hadoop.env
    volumes:
      - ${DP_INPUT_SETUP_DIR}/spark:/opt/data-setup/spark
      - ${DP_DATA_DIR}/spark-client:/opt/data/spark/logs
      - ${DP_INPUT_DIR}/spark-client:/opt/data/spark/jars

  b-loader:
#    image: da-platform/h-hive-base:2.3.8
    image: megoldsby/da-platform:h-hive-base-2.3.8
    container_name: b-loader
    volumes:
      - ${DP_INPUT_SETUP_DIR}/hive:/opt/data/data-setup
      - ${DP_INPUT_DIR}/hive:/opt/data/input

  v-loader:
#    image: da-platform/v-loader:9.2.1-centos7
    image: megoldsby/da-platform:v-loader-9.2.1-centos7
    container_name: v-loader
    volumes:
      - ${DP_INPUT_SETUP_DIR}/vertica:/opt/data/data-setup
      - ${DP_INPUT_DIR}/vertica:/opt/data/input
      - ${DP_INPUT_DIR}/vertica/logs:/opt/data/logs

  vertica:
#    image: da-platform/vertica:9.2.1-centos7
    image: megoldsby/da-platform:vertica-9.2.1-centos7
    container_name: vertica
    volumes:
      - ${DP_DATA_DIR}/vertica:/home/dbadmin/da-platform
    ports:
      - 5433:5433

  spark-proxy:
#    image: da-platform/spark-proxy:2.4.3-hadoop2.10.1-java8
    image: megoldsby/da-platform:spark-proxy-2.4.3-hadoop2.10.1-java8
    container_name: spark_proxy
    environment:
      - SPARK_MASTER=yarn
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file:
      - ./hadoop.env
    volumes:
      - ${DP_INPUT_SETUP_DIR}/spark:/opt/data-setup/spark
      - ${DP_DATA_DIR}/spark-proxy:/opt/data/spark/logs
      - ${DP_INPUT_DIR}/spark-proxy:/opt/data/spark/jars
    ports:
      - "2222:22"

  python-proxy:
#    image: da-platform/python-proxy:3.9-slim-buster
    image: megoldsby/da-platform:python-proxy-3.9-slim-buster
    container_name: python_proxy
    hostname: python_proxy
    volumes:
      - ${DP_DATA_DIR}/python-proxy:/opt/data/output
      - ${DP_INPUT_DIR}/python-proxy/output:/opt/data/input
    ports:
      - "2221:22"

  apache-knox:
#    image: da-platform/apache-knox:1.4.0
      image: megoldsby/da-platform:apache-knox-1.4.0
      container_name: apache-knox
      ports:
          - "8080:8080"
          - "8443:8443"
      volumes:
        - ${DP_DATA_DIR}/knox:/opt/knox/logs

  namenode:
#    image: da-platform/h-namenode:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-namenode-2.0.0-hadoop2.10.1-java8
    container_name: h_namenode
    volumes:
      - ${DP_DATA_DIR}/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    ports:
      - 50070:50070
      - 8020:8020

  datanode1:
#    image: da-platform/h-datanode:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-datanode-2.0.0-hadoop2.10.1-java8
    depends_on: 
      - namenode
    volumes:
      - ${DP_DATA_DIR}/datanode1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    ports:
      - 50075:50075

  datanode2:
#    image: da-platform/h-datanode:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-datanode-2.0.0-hadoop2.10.1-java8
    depends_on: 
      - namenode
    volumes:
      - ${DP_DATA_DIR}/datanode2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env

  datanode3:
#    image: da-platform/h-datanode:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-datanode-2.0.0-hadoop2.10.1-java8
    depends_on: 
      - namenode
    volumes:
      - ${DP_DATA_DIR}/datanode3:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
 
  resourcemanager:
#    image: da-platform/h-resourcemanager:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-resourcemanager-2.0.0-hadoop2.10.1-java8
    container_name: h_resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode2:50075 datanode3:50075"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    ports:
      - 8088:8088

  nodemanager:
#    image: da-platform/h-nodemanager:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-nodemanager-2.0.0-hadoop2.10.1-java8
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode2:50075 datanode3:50075 resourcemanager:8088"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    scale: $DA_YARN_NODE_SCALE
#    ports:
#      - 8042:8042

  historyserver:
#    image: da-platform/h-historyserver:2.0.0-hadoop2.10.1-java8
    image: megoldsby/da-platform:h-historyserver-2.0.0-hadoop2.10.1-java8
    container_name: h_historyserver
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode2:50075 datanode3:50075 resourcemanager:8088"
    volumes:
      - ${DP_DATA_DIR}/yarn/timeline:/hadoop/yarn/timeline
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    ports:
      - "8188:8188"

  hive-server:
#    image: da-platform/h-hive-server:2.3.8
    image: megoldsby/da-platform:h-hive-server-2.3.8
    container_name: h_hiveserver
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    volumes:
      - ${DP_INPUT_DIR}/hive:/opt/data/input
    ports:
      - "10000:10000"
      - "10002:10002"

  hive-metastore:
#    image: da-platform/h-hive-server:2.3.8
    image: megoldsby/da-platform:h-hive-server-2.3.8
    container_name: h_hivemetastore
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode1:50075 datanode2:50075 datanode3:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
#    image: da-platform/hive-metastore-postgresql:2.3.0
    image: megoldsby/da-platform:hive-metastore-postgresql-2.3.0
    container_name: h_hivemetastore_postgresql
    volumes:
      - ${DP_DATA_DIR}/postgres:/var/lib/postgresql/data
    environment:
      PGDATA: /tmp
    ports:
      - 5432:5432

  spark-livy:
#    image: da-platform/spark-livy:2.4.3-hadoop2.7
    image: megoldsby/da-platform:spark-livy-2.4.3-hadoop2.7
    container_name: spark-livy
    volumes:
      - ${DP_DATA_DIR}/livy:/opt/apache-livy-bin/logs
    ports:
      - 8998:8998

  zeppelin:
#    image: da-platform/zeppelin:0.8.2-spark2.4 
    image: megoldsby/da-platform:zeppelin-0.8.2-spark2.4 
    container_name: zeppelin
    ports:
      - "8282:8080"
    env_file:
      - ${DP_SETUP_DIR}/hadoop.env
    volumes:
      - ${DP_INPUT_SETUP_DIR}/z-notebook:/opt/zeppelin/notebook
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      #- SPARK_MASTER=spark://spark-master:7077
      - MASTER=yarn-client
      #SPARK_SUBMIT_OPTIONS: "--jars /opt/sansa-examples/jars/sansa-examples-spark-2016-12.jar"

  hue:
    image: gethue/hue:latest
#      hostname: hue
    container_name: hue
#     dns: 8.8.8.8
    environment:
      SERVICE_PRECONDITION: "mysql-db:3306"
    ports:
      - "8888:8888"
    volumes:
      - ${DP_SETUP_DIR}/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      - "mysql-db"

  mysql-db:
      image: mysql:5.7
      container_name: mysql-db
      ports:
          - "3306:3306"
      command: --init-file /data/application/init.sql
      volumes:
          - ${DP_DATA_DIR}/mysql:/var/lib/mysql
          - ${DP_SETUP_DIR}/init-hue.sql:/data/application/init.sql
      environment:
          MYSQL_ROOT_USER: root
          MYSQL_ROOT_PASSWORD: secret
          MYSQL_DATABASE: hue
#          MYSQL_USER: root
#          MYSQL_PASSWORD: secret

## Concourse related images

  cc-fly:
    image: megoldsby/da-platform:fly-7.1.0-alpine
    container_name: cc-fly    
    volumes:
        - ${DP_INPUT_SETUP_DIR}/concourse:/concourse

  cc-db:
    image: postgres
    container_name: cc-db
    hostname: cc-db
    environment:
      POSTGRES_DB: concourse
      POSTGRES_USER: concourse_user
      POSTGRES_PASSWORD: concourse_pass
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "10m"

  cc-web:
    image: concourse/concourse:7.1.0-ubuntu
    container_name: cc-web
    hostname: cc-web
    command: web
    links: [cc-db]
    depends_on: [cc-db]
    ports: ["8181:8080"]
    volumes: ["./cc-keys/web:/concourse-keys"]
    environment:
      CONCOURSE_EXTERNAL_URL: http://localhost:8181
      CONCOURSE_POSTGRES_HOST: cc-db
      CONCOURSE_POSTGRES_USER: concourse_user
      CONCOURSE_POSTGRES_PASSWORD: concourse_pass
      CONCOURSE_POSTGRES_DATABASE: concourse
      CONCOURSE_ADD_LOCAL_USER: test:test
      CONCOURSE_MAIN_TEAM_LOCAL_USER: test
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "10m"

  cc-worker:
    image: concourse/concourse:7.1.0-ubuntu
    container_name: cc-worker
    hostname: cc-worker
    command: worker
    privileged: true
    depends_on: [cc-web]
    volumes: ["./cc-keys/worker:/concourse-keys"]
    links: [cc-web]
    stop_signal: SIGUSR2
    environment:
      CONCOURSE_TSA_HOST: cc-web:2222
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "10m"


